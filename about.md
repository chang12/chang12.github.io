---
layout: page
title: About
permalink: /about/
---

데이터 잡부로 일하고 있습니다. 배치 데이터 파이프라인을 개발할 때는 Apache Spark 와 Apache Airflow 를 사용합니다. Airflow 는 GCP 의 매니지드 서비스인 Cloud Composer 로 운영합니다. k8s 환경에 컴포넌트들을 배포하여 운영해보고 싶은 욕심이 있는데 근 시일내에 그럴 시간이 주어질지 모르겠습니다. Spark 는 Amazon EMR 클러스터와 AWS Fargate 환경으로 실행합니다. 로그 파이프라인은 많이들 사용하는 패턴인 Kinesis -> Firehose -> S3 로 떨구고 보는 패턴을 사용합니다. 진정한 의미의 스트리밍 어플리케이션은 운영해본 적 없습니다. 데이터 웨어하우스로는 BigQuery 를 사랑하지만 사정상 현재는 Redshift 를 사용하고 있습니다. 곧 넘어갈 수 있으리란 희망을 가지고 있습니다. SQL 은 능숙하지만 Python 으로 데이터 처리하는 것은 어색합니다. 예전에는 ML 파이프라인에도 관심이 많았었는데 요새는 ML 모델의 효용을 직접 느끼기에는 좀 멀리 있고, 그보다 가까이에 있는 문제들이 더 크게 다가와서 별 생각 못하고 있습니다.
